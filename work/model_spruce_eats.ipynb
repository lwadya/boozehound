{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model Using Spruce Eats Data\n",
    "I used the scraped and cleaned Spruce Eats data to build a recommender engine in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and Functions\n",
    "* **var_to_pickle**: Writes the given variable to a pickle file\n",
    "* **read_pickle**: Reads the given pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from code.lw_pickle import var_to_pickle, read_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load DataFrame From Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pk = '../data/se_df.pk'\n",
    "df = read_pickle(df_pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-process Descriptions\n",
    "In this section I lemmatize descriptions using Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scy = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple script that lemmatizes lists of names and base spirits\n",
    "def list_prepro(items):\n",
    "    item_str = ' '.join(set([i for row in items for i in row]))\n",
    "    doc = scy(item_str)\n",
    "    words = [token.lemma_ for token in doc]\n",
    "    words = list(set(filter(lambda w: '-' not in w, words)))\n",
    "    return words\n",
    "\n",
    "# Simple script that lemmatizes a description\n",
    "def desc_prepro(desc):\n",
    "    pos_keep = ['ADJ', 'NOUN', 'PROPN']\n",
    "    doc = scy(desc)\n",
    "    words = [token.lemma_ for token in doc if token.pos_ in pos_keep]\n",
    "    words = list(filter(lambda w: '-' not in w, words))\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df['description'].map(desc_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Lists of Stop Words\n",
    "I created separate lists of stop words for two models: one includes several shared stop words and the other is more aggressive, containing drink names and base spirits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually-populated list of generic stop words\n",
    "gen_stop_words = ['cocktail', 'drink', 'recipe', 'make', 'mix', 'flavor', 'good',\n",
    "                  'ingredient', 'taste', 'perfect', 'little', 'bar', 'nice', 'blue',\n",
    "                  'great', 'way', 'favorite', 'new', 'popular', 'delicious', 'green',\n",
    "                  'party', 'fun', 'black', 'sure', 'time', 'glass', 'woo', 'year',\n",
    "                  'st', 'shot', 'garnish', 'pink', 'bit', 'different', 'choice',\n",
    "                  'drink', 'bartender', 'recipe', 'fantastic', 'delicious', 'use',\n",
    "                  'taste', 'nice', 'liquor', 'drink', 'bit', 'drinker', 'try']\n",
    "safe_sw = text.ENGLISH_STOP_WORDS.union(gen_stop_words)\n",
    "\n",
    "# Lemmatized lists of base spirits and drink names\n",
    "base_spirits = list_prepro(df['base_spirits'].tolist())\n",
    "name_words = list_prepro(df['name_words'].tolist())\n",
    "\n",
    "fun_sw = text.ENGLISH_STOP_WORDS.union(gen_stop_words + base_spirits + name_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Safe NMF Recommender\n",
    "This recommender is based on the less aggressive, safe stop words list and returns predictions that contain similar names and base spirits as a given cocktail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF Matrix\n",
    "safe_tfidf = TfidfVectorizer(stop_words=safe_sw)\n",
    "safe_mtx = safe_tfidf.fit_transform(descriptions.values)\n",
    "\n",
    "# Create NMF Vectors\n",
    "safe_nmf = NMF(n_components = 30)\n",
    "safe_drink_vec = safe_nmf.fit_transform(safe_mtx)\n",
    "safe_word_vec = safe_nmf.components_.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Fun NMF Recommender\n",
    "This recommender is based on the more aggressive stop words list and returns predictions that can differ wildly from a given cocktail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF Matrix\n",
    "fun_tfidf = TfidfVectorizer(stop_words=fun_sw)\n",
    "fun_mtx = fun_tfidf.fit_transform(descriptions.values)\n",
    "\n",
    "# Create NMF Vectors\n",
    "fun_nmf = NMF(n_components = 25)\n",
    "fun_drink_vec = fun_nmf.fit_transform(fun_mtx)\n",
    "fun_word_vec = fun_nmf.components_.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create Recommender Class\n",
    "This class serves as a data container for the models, vectors, and DataFrame needed to make the recommendation engine work properly. It also has a recommend function for simple compatibility with the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cocktail_recommender:\n",
    "    dist_metric = 'cosine'\n",
    "    drink_weight = .4\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Connects important data structures to class variables\n",
    "        self.df = df\n",
    "        #self.scy = scy\n",
    "        self.safe_tfidf = safe_tfidf\n",
    "        self.safe_nmf = safe_nmf\n",
    "        self.safe_drink_vec = safe_drink_vec\n",
    "        self.fun_tfidf = fun_tfidf\n",
    "        self.fun_nmf = fun_nmf\n",
    "        self.fun_drink_vec = fun_drink_vec\n",
    "        \n",
    "        # Creates a series of sets representing drink names\n",
    "        self.name_sets = self.df['name_words'].apply(set)\n",
    "        \n",
    "    # Recommend function\n",
    "    def recommend(self, input_string, weirdness=.5, num_recos=10, exclude_inputs=True):\n",
    "        if not input_string:\n",
    "            return False, None\n",
    "        weirdness = max(min(weirdness, 1), 0)\n",
    "        name_set = search_set = self.clean_input(input_string)\n",
    "        drink_idx = self.name_matches(name_set)\n",
    "        \n",
    "        # Calculates safe search vector\n",
    "        safe_search_vec = (self.safe_nmf.transform(\n",
    "                           self.safe_tfidf.transform(search_set)))\n",
    "        safe_search_vec = np.mean(safe_search_vec, axis=0, keepdims=True)\n",
    "        \n",
    "        # Calculates fun search vector\n",
    "        fun_search_vec = (self.fun_nmf.transform(\n",
    "                          self.fun_tfidf.transform(search_set)))\n",
    "        fun_search_vec = np.mean(fun_search_vec, axis=0, keepdims=True)\n",
    "        \n",
    "        # Averages search vectors with matched drink vectors\n",
    "        if drink_idx:\n",
    "            safe_drink_vec = np.mean(self.safe_drink_vec[[drink_idx]],\n",
    "                                     axis=0,\n",
    "                                     keepdims=True)\n",
    "            fun_drink_vec = np.mean(self.fun_drink_vec[[drink_idx]],\n",
    "                                    axis=0,\n",
    "                                    keepdims=True)\n",
    "            safe_search_vec = ((1 - self.drink_weight) * safe_search_vec +\n",
    "                               self.drink_weight * safe_drink_vec)\n",
    "            fun_search_vec = ((1 - self.drink_weight) * fun_search_vec +\n",
    "                               self.drink_weight * fun_drink_vec)\n",
    "            \n",
    "        # Calculates pairwise distances between search vectors and recommendations\n",
    "        if not safe_search_vec.sum():\n",
    "            return False, None\n",
    "        elif not fun_search_vec.sum():\n",
    "            dist = pairwise_distances(X=self.safe_drink_vec,\n",
    "                                      Y=safe_search_vec,\n",
    "                                      metric=self.dist_metric)\n",
    "        else:\n",
    "            safe_dist = pairwise_distances(X=self.safe_drink_vec,\n",
    "                                           Y=safe_search_vec,\n",
    "                                           metric=self.dist_metric)\n",
    "            fun_dist = pairwise_distances(X=self.fun_drink_vec,\n",
    "                                          Y=fun_search_vec,\n",
    "                                          metric=self.dist_metric)\n",
    "            dist = (1 - weirdness) * safe_dist + weirdness * fun_dist\n",
    "           \n",
    "        # Calculates recommendations\n",
    "        rank_idx = dist.transpose()[0].argsort().tolist()\n",
    "        if exclude_inputs:\n",
    "            rank_idx = list(filter(lambda x: x not in drink_idx, rank_idx))\n",
    "        return True, self.df.loc[rank_idx].head(num_recos)\n",
    "            \n",
    "    # Cleans input string for title match and NMF vectorization\n",
    "    def clean_input(self, input_string):\n",
    "        clean_str = re.sub('[^a-z0-9 \\-]', '', input_string.lower().strip())\n",
    "        #doc = self.scy(clean_str)\n",
    "        #words = [token.lemma_ for token in doc]\n",
    "        return set(clean_str.split())#, set(words)\n",
    "    \n",
    "    # Find cocktail name matches in input set\n",
    "    def name_matches(self, input_set):\n",
    "        mask = (self.name_sets - input_set) == set()\n",
    "        return self.name_sets[mask].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = cocktail_recommender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Recommender Testing\n",
    "Cell for simple testing calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613      rustic manhattan\n",
       "549      plantation fever\n",
       "45         banana hammock\n",
       "267    frozen pina colada\n",
       "772           yellow bird\n",
       "181       coconut martini\n",
       "510                paloma\n",
       "687    surprised cocktail\n",
       "90            blue blazer\n",
       "612            rum runner\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr.recommend('rum', exclude_inputs=False, weirdness=.5)['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Pickle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_pk = '../data/reco.pk'\n",
    "var_to_pickle(cr, reco_pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
